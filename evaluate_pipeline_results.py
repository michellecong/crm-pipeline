#!/usr/bin/env python3
"""
Pipeline Evaluation Script

è¯„ä¼°ä¸‰ç§æ¶æ„ï¼ˆ2-stage, 3-stage, 4-stageï¼‰çš„æµ‹è¯•ç»“æœ
åªå¯¹æ¯”æœ‰æ„ä¹‰çš„æŒ‡æ ‡ï¼š
- 2 Stage vs 3 Stage çš„ Personasï¼ˆç”Ÿæˆæ–¹æ³•ä¸åŒï¼‰
- 2 Stage vs 3 Stage vs 4 Stage çš„ Mappingsï¼ˆç”Ÿæˆæ–¹æ³•ä¸åŒï¼‰
- 2 Stage vs 3 Stage vs 4 Stage çš„ Sequencesï¼ˆç”Ÿæˆæ–¹æ³•ä¸åŒï¼‰
"""
import json
from pathlib import Path
from typing import Dict
import pandas as pd
from datetime import datetime


# è¯„ä¼°æ•°æ®ç›®å½•
EVALUATION_DIR = Path("data/Evaluation")


def normalize_architecture_name(name: str) -> str:
    """ç»Ÿä¸€æ¶æ„åç§°ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰"""
    name_lower = name.lower().strip()
    if "2" in name_lower and "stage" in name_lower:
        return "Two-Stage"
    elif "3" in name_lower and "stage" in name_lower:
        return "Three-Stage"
    elif "4" in name_lower and "stage" in name_lower:
        return "Four-Stage"
    return name


def remove_outliers(series: pd.Series, method: str = "iqr", multiplier: float = 1.5) -> pd.Series:
    """
    ç§»é™¤å¼‚å¸¸å€¼
    
    Args:
        series: æ•°æ®åºåˆ—
        method: æ£€æµ‹æ–¹æ³• ("iqr" æˆ– "zscore")
        multiplier: IQRæ–¹æ³•çš„å€æ•°ï¼ˆé»˜è®¤1.5ï¼‰
    
    Returns:
        ç§»é™¤å¼‚å¸¸å€¼åçš„åºåˆ—
    """
    if len(series) < 3:
        return series
    
    if method == "iqr":
        Q1 = series.quantile(0.25)
        Q3 = series.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - multiplier * IQR
        upper_bound = Q3 + multiplier * IQR
        return series[(series >= lower_bound) & (series <= upper_bound)]
    elif method == "zscore":
        z_scores = (series - series.mean()) / series.std()
        return series[abs(z_scores) < 3]  # 3ä¸ªæ ‡å‡†å·®
    else:
        return series


class PipelineEvaluator:
    """è¯„ä¼°pipelineç»“æœçš„ç±»"""

    def __init__(self, evaluation_dir: Path):
        self.evaluation_dir = evaluation_dir
        self.results = []

    def load_company_data(self, company_name: str, architecture: str) -> Dict:
        """åŠ è½½æŸä¸ªå…¬å¸åœ¨æŸä¸ªæ¶æ„ä¸‹çš„æ‰€æœ‰æ•°æ®"""
        company_base_dir = self.evaluation_dir / company_name
        
        # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        company_dir = company_base_dir / architecture
        if not company_dir.exists():
            # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
            if company_base_dir.exists():
                for subdir in company_base_dir.iterdir():
                    if subdir.is_dir() and subdir.name.lower() == architecture.lower():
                        company_dir = subdir
                        break
                else:
                    return {}
            else:
                return {}

        # å½’ä¸€åŒ–æ¶æ„åç§°ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        normalized_architecture = normalize_architecture_name(architecture)

        data = {
            "company_name": company_name,
            "architecture": normalized_architecture,
            "products": None,
            "personas": None,
            "mappings": None,
            "sequences": None,
            "two_stage": None,
            "three_stage": None,
        }

        # åŠ è½½æ‰€æœ‰JSONæ–‡ä»¶
        for json_file in company_dir.glob("*.json"):
            filename = json_file.stem.lower()

            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    content = json.load(f)

                # æ ¹æ®æ–‡ä»¶ååˆ¤æ–­ç±»å‹
                if "product" in filename:
                    data["products"] = content
                elif "persona" in filename and "mapping" not in filename:
                    data["personas"] = content
                elif "mapping" in filename:
                    data["mappings"] = content
                elif "outreach" in filename or "sequence" in filename:
                    data["sequences"] = content
                elif "two_stage" in filename:
                    data["two_stage"] = content
                elif "three_stage" in filename:
                    data["three_stage"] = content

            except Exception as e:
                print(f"Error loading {json_file}: {e}")

        return data

    def extract_metrics(self, data: Dict) -> Dict:
        """ä»æ•°æ®ä¸­æå–è¯„ä¼°æŒ‡æ ‡"""
        metrics = {
            "company_name": data["company_name"],
            "architecture": normalize_architecture_name(data["architecture"]),
            "num_products": 0,
            "num_personas": 0,
            "num_mappings": 0,
            "num_sequences": 0,
            "num_touches": 0,
            "avg_mappings_per_persona": 0,
            "avg_touches_per_sequence": 0,
            "total_tokens": 0,
            "total_time_seconds": 0,
            "prompt_tokens": 0,
            "completion_tokens": 0,
        }

        # æå–ProductsæŒ‡æ ‡
        if data.get("products"):
            products_data = data["products"].get("result", {}).get("products", [])
            metrics["num_products"] = len(products_data)

        # æå–PersonasæŒ‡æ ‡
        personas_data = []
        if data.get("personas"):
            personas_data = data["personas"].get("result", {}).get("personas", [])
        elif data.get("two_stage"):
            personas_data = data["two_stage"].get("result", {}).get("personas", [])
        elif data.get("three_stage"):
            # Three-stageæ²¡æœ‰å•ç‹¬çš„personasæ–‡ä»¶ï¼Œpersonasåœ¨mappingsä¸­
            mappings_data = data["three_stage"].get("result", {}).get("personas_with_mappings", [])
            # ä»mappingsä¸­æå–personaåç§°ä½œä¸ºpersonas
            personas_data = [{"persona_name": p.get("persona_name")} for p in mappings_data]

        metrics["num_personas"] = len(personas_data)

        # æå–MappingsæŒ‡æ ‡
        mappings_data = []
        if data.get("mappings"):
            mappings_data = data["mappings"].get("result", {}).get("personas_with_mappings", [])
        elif data.get("two_stage"):
            mappings_data = data["two_stage"].get("result", {}).get("personas_with_mappings", [])
        elif data.get("three_stage"):
            mappings_data = data["three_stage"].get("result", {}).get("personas_with_mappings", [])

        metrics["num_mappings"] = sum(len(p.get("mappings", [])) for p in mappings_data)
        if metrics["num_personas"] > 0:
            metrics["avg_mappings_per_persona"] = metrics["num_mappings"] / metrics["num_personas"]

        # æå–SequencesæŒ‡æ ‡
        sequences_data = []
        if data.get("sequences"):
            sequences_data = data["sequences"].get("result", {}).get("sequences", [])
        elif data.get("two_stage"):
            sequences_data = data["two_stage"].get("result", {}).get("sequences", [])
        elif data.get("three_stage"):
            sequences_data = data["three_stage"].get("result", {}).get("sequences", [])

        metrics["num_sequences"] = len(sequences_data)
        metrics["num_touches"] = sum(len(s.get("touches", [])) for s in sequences_data)
        if metrics["num_sequences"] > 0:
            metrics["avg_touches_per_sequence"] = metrics["num_touches"] / metrics["num_sequences"]

        # æå–Tokenå’Œæ—¶é—´æŒ‡æ ‡
        usage_data = None
        time_data = None

        # åˆ¤æ–­æ˜¯å¦ä¸ºå››é˜¶æ®µæ¶æ„ï¼ˆæœ‰ç‹¬ç«‹çš„products, personas, mappings, sequencesæ–‡ä»¶ï¼‰
        is_four_stage = (
            data.get("products") is not None
            and data.get("personas") is not None
            and data.get("mappings") is not None
            and data.get("sequences") is not None
            and data.get("two_stage") is None
            and data.get("three_stage") is None
        )

        if is_four_stage:
            # å››é˜¶æ®µæ¶æ„ï¼šåˆ†åˆ«ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶çš„tokenå’Œæ—¶é—´
            # Products
            if data.get("products"):
                products_result = data["products"].get("result", {})
                products_usage = products_result.get("usage", {})
                products_time = products_result.get("generation_time_seconds", 0)
                if products_usage:
                    metrics["prompt_tokens"] += products_usage.get("prompt_tokens", 0)
                    metrics["completion_tokens"] += products_usage.get("completion_tokens", 0)
                    metrics["total_tokens"] += products_usage.get("total_tokens", 0)
                if products_time:
                    metrics["total_time_seconds"] += products_time

            # Personas
            if data.get("personas"):
                personas_result = data["personas"].get("result", {})
                personas_usage = personas_result.get("usage", {})
                personas_time = personas_result.get("generation_time_seconds", 0)
                if personas_usage:
                    metrics["prompt_tokens"] += personas_usage.get("prompt_tokens", 0)
                    metrics["completion_tokens"] += personas_usage.get("completion_tokens", 0)
                    metrics["total_tokens"] += personas_usage.get("total_tokens", 0)
                if personas_time:
                    metrics["total_time_seconds"] += personas_time

            # Mappings
            if data.get("mappings"):
                mappings_result = data["mappings"].get("result", {})
                mappings_usage = mappings_result.get("usage", {})
                mappings_time = mappings_result.get("generation_time_seconds", 0)
                if mappings_usage:
                    metrics["prompt_tokens"] += mappings_usage.get("prompt_tokens", 0)
                    metrics["completion_tokens"] += mappings_usage.get("completion_tokens", 0)
                    metrics["total_tokens"] += mappings_usage.get("total_tokens", 0)
                if mappings_time:
                    metrics["total_time_seconds"] += mappings_time

            # Sequences
            if data.get("sequences"):
                sequences_result = data["sequences"].get("result", {})
                sequences_usage = sequences_result.get("usage", {})
                sequences_time = sequences_result.get("generation_time_seconds", 0)
                if sequences_usage:
                    metrics["prompt_tokens"] += sequences_usage.get("prompt_tokens", 0)
                    metrics["completion_tokens"] += sequences_usage.get("completion_tokens", 0)
                    metrics["total_tokens"] += sequences_usage.get("total_tokens", 0)
                if sequences_time:
                    metrics["total_time_seconds"] += sequences_time
        else:
            # ä¸¤é˜¶æ®µæˆ–ä¸‰é˜¶æ®µæ¶æ„ï¼šä»consolidatedæ–‡ä»¶æå–
            if data.get("two_stage"):
                result = data["two_stage"].get("result", {})
                usage_data = result.get("usage", {})
                time_data = result.get("generation_time_seconds")
            elif data.get("three_stage"):
                result = data["three_stage"].get("result", {})
                usage_data = result.get("usage", {})
                time_data = result.get("generation_time_seconds")

            # ä»productsæ–‡ä»¶æå–ï¼ˆå¦‚æœæœ‰ï¼Œä¸¤é˜¶æ®µå’Œä¸‰é˜¶æ®µä¹Ÿå¯èƒ½æœ‰ç‹¬ç«‹çš„productsæ–‡ä»¶ï¼‰
            if data.get("products"):
                products_result = data["products"].get("result", {})
                products_usage = products_result.get("usage", {})
                products_time = products_result.get("generation_time_seconds", 0)
                if products_usage:
                    metrics["prompt_tokens"] += products_usage.get("prompt_tokens", 0)
                    metrics["completion_tokens"] += products_usage.get("completion_tokens", 0)
                    metrics["total_tokens"] += products_usage.get("total_tokens", 0)
                if products_time:
                    metrics["total_time_seconds"] += products_time

            # ä»personasæ–‡ä»¶æå–ï¼ˆThree-Stageæœ‰ç‹¬ç«‹çš„personasæ–‡ä»¶ï¼‰
            if data.get("personas"):
                personas_result = data["personas"].get("result", {})
                personas_usage = personas_result.get("usage", {})
                personas_time = personas_result.get("generation_time_seconds", 0)
                if personas_usage:
                    metrics["prompt_tokens"] += personas_usage.get("prompt_tokens", 0)
                    metrics["completion_tokens"] += personas_usage.get("completion_tokens", 0)
                    metrics["total_tokens"] += personas_usage.get("total_tokens", 0)
                if personas_time:
                    metrics["total_time_seconds"] += personas_time

            # ä»sequences/outreachæ–‡ä»¶æå–ï¼ˆå¦‚æœæœ‰ç‹¬ç«‹çš„sequencesæ–‡ä»¶ï¼‰
            if data.get("sequences"):
                sequences_result = data["sequences"].get("result", {})
                sequences_usage = sequences_result.get("usage", {})
                sequences_time = sequences_result.get("generation_time_seconds", 0)
                if sequences_usage:
                    metrics["prompt_tokens"] += sequences_usage.get("prompt_tokens", 0)
                    metrics["completion_tokens"] += sequences_usage.get("completion_tokens", 0)
                    metrics["total_tokens"] += sequences_usage.get("total_tokens", 0)
                if sequences_time:
                    metrics["total_time_seconds"] += sequences_time

            # ä»consolidatedæ–‡ä»¶æå–ï¼ˆtwo_stageæˆ–three_stageï¼‰
            if usage_data:
                metrics["prompt_tokens"] += usage_data.get("prompt_tokens", 0)
                metrics["completion_tokens"] += usage_data.get("completion_tokens", 0)
                metrics["total_tokens"] += usage_data.get("total_tokens", 0)

            if time_data:
                metrics["total_time_seconds"] += time_data

        return metrics

    def evaluate_all(self) -> pd.DataFrame:
        """è¯„ä¼°æ‰€æœ‰å…¬å¸çš„æ‰€æœ‰æ¶æ„"""
        all_metrics = []

        # éå†æ‰€æœ‰å…¬å¸
        for company_dir in self.evaluation_dir.iterdir():
            if not company_dir.is_dir():
                continue

            company_name = company_dir.name

            # éå†æ‰€æœ‰æ¶æ„
            for arch_dir in company_dir.iterdir():
                if not arch_dir.is_dir():
                    continue

                # åŠ è½½æ•°æ®ï¼ˆæ¶æ„åç§°ä¼šåœ¨load_company_dataä¸­å½’ä¸€åŒ–ï¼‰
                data = self.load_company_data(company_name, arch_dir.name)

                if not data:
                    continue

                # æå–æŒ‡æ ‡
                metrics = self.extract_metrics(data)
                all_metrics.append(metrics)

        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(all_metrics)
        return df

    def generate_time_token_analysis(self, df: pd.DataFrame) -> Dict:
        """ç”Ÿæˆæ—¶é—´å’ŒTokençš„è¯¦ç»†å¯¹æ¯”åˆ†æ"""
        analysis = {
            "time_analysis": {},
            "token_analysis": {},
            "efficiency_metrics": {},
            "stage_breakdown": {},
            "comparison_summary": {}
        }
        
        # æŒ‰æ¶æ„åˆ†ç»„
        for arch in ["Two-Stage", "Three-Stage", "Four-Stage"]:
            arch_df = df[df["architecture"] == arch]
            if len(arch_df) == 0:
                continue
            
            # æ—¶é—´åˆ†æ
            time_series = arch_df["total_time_seconds"]
            time_without_outliers = remove_outliers(time_series, method="iqr", multiplier=1.5)
            
            analysis["time_analysis"][arch] = {
                "mean": float(time_series.mean()),
                "median": float(time_series.median()),
                "std": float(time_series.std()) if len(time_series) > 1 else 0.0,
                "min": float(time_series.min()),
                "max": float(time_series.max()),
                "mean_without_outliers": float(time_without_outliers.mean()) if len(time_without_outliers) > 0 else float(time_series.mean()),
                "count": int(len(time_series)),
                "count_without_outliers": int(len(time_without_outliers))
            }
            
            # Tokenåˆ†æ
            token_series = arch_df["total_tokens"]
            prompt_tokens = arch_df["prompt_tokens"].sum()
            completion_tokens = arch_df["completion_tokens"].sum()
            
            analysis["token_analysis"][arch] = {
                "total_tokens_mean": float(token_series.mean()),
                "total_tokens_median": float(token_series.median()),
                "total_tokens_std": float(token_series.std()) if len(token_series) > 1 else 0.0,
                "total_tokens_min": float(token_series.min()),
                "total_tokens_max": float(token_series.max()),
                "prompt_tokens_total": int(prompt_tokens),
                "completion_tokens_total": int(completion_tokens),
                "prompt_tokens_mean": float(arch_df["prompt_tokens"].mean()),
                "completion_tokens_mean": float(arch_df["completion_tokens"].mean()),
                "prompt_ratio": float(prompt_tokens / token_series.sum() * 100) if token_series.sum() > 0 else 0.0,
                "completion_ratio": float(completion_tokens / token_series.sum() * 100) if token_series.sum() > 0 else 0.0,
                "count": int(len(token_series))
            }
            
            # æ•ˆç‡æŒ‡æ ‡
            avg_time = analysis["time_analysis"][arch]["mean_without_outliers"]
            avg_tokens = analysis["token_analysis"][arch]["total_tokens_mean"]
            avg_mappings = float(arch_df["num_mappings"].mean())
            avg_sequences = float(arch_df["num_sequences"].mean())
            
            analysis["efficiency_metrics"][arch] = {
                "tokens_per_second": float(avg_tokens / avg_time) if avg_time > 0 else 0.0,
                "mappings_per_token": float(avg_mappings / avg_tokens) if avg_tokens > 0 else 0.0,
                "sequences_per_token": float(avg_sequences / avg_tokens) if avg_tokens > 0 else 0.0,
                "mappings_per_second": float(avg_mappings / avg_time) if avg_time > 0 else 0.0,
                "sequences_per_second": float(avg_sequences / avg_time) if avg_time > 0 else 0.0,
                "time_per_mapping": float(avg_time / avg_mappings) if avg_mappings > 0 else 0.0,
                "time_per_sequence": float(avg_time / avg_sequences) if avg_sequences > 0 else 0.0
            }
        
        # å¯¹æ¯”æ€»ç»“ï¼ˆç›¸å¯¹äº2-Stageçš„å˜åŒ–ï¼‰
        two_stage_time = analysis["time_analysis"].get("Two-Stage", {}).get("mean_without_outliers", 0)
        two_stage_tokens = analysis["token_analysis"].get("Two-Stage", {}).get("total_tokens_mean", 0)
        
        for arch in ["Three-Stage", "Four-Stage"]:
            if arch in analysis["time_analysis"]:
                arch_time = analysis["time_analysis"][arch]["mean_without_outliers"]
                arch_tokens = analysis["token_analysis"][arch]["total_tokens_mean"]
                
                analysis["comparison_summary"][arch] = {
                    "time_vs_two_stage": {
                        "absolute_change": float(arch_time - two_stage_time),
                        "percentage_change": float((arch_time - two_stage_time) / two_stage_time * 100) if two_stage_time > 0 else 0.0,
                        "multiplier": float(arch_time / two_stage_time) if two_stage_time > 0 else 0.0
                    },
                    "tokens_vs_two_stage": {
                        "absolute_change": float(arch_tokens - two_stage_tokens),
                        "percentage_change": float((arch_tokens - two_stage_tokens) / two_stage_tokens * 100) if two_stage_tokens > 0 else 0.0,
                        "multiplier": float(arch_tokens / two_stage_tokens) if two_stage_tokens > 0 else 0.0
                    }
                }
        
        return analysis

    def generate_meaningful_comparison(self, df: pd.DataFrame) -> Dict:
        """ç”Ÿæˆæœ‰æ„ä¹‰çš„æ¶æ„å¯¹æ¯”ï¼ˆåªå¯¹æ¯”ç”Ÿæˆæ–¹æ³•ä¸åŒçš„éƒ¨åˆ†ï¼‰"""
        comparison = {
            "personas_comparison": {},
            "mappings_comparison": {},
            "sequences_comparison": {},
            "overall_performance": {},
            "time_token_analysis": {},
            "notes": []
        }
        
        # 1. Personaså¯¹æ¯”ï¼š2 Stage vs 4 Stageï¼ˆ3 Stage å’Œ 4 Stage çš„ Personas æ˜¯ä¸€æ ·çš„ï¼‰
        two_stage_personas = df[df["architecture"] == "Two-Stage"]["num_personas"]
        four_stage_personas = df[df["architecture"] == "Four-Stage"]["num_personas"]

        if len(two_stage_personas) > 0 and len(four_stage_personas) > 0:
            comparison["personas_comparison"] = {
                "two_stage": {
                    "avg": float(two_stage_personas.mean()),
                    "std": float(two_stage_personas.std()) if len(two_stage_personas) > 1 else 0.0,
                    "count": int(len(two_stage_personas))
                },
                "four_stage": {
                    "avg": float(four_stage_personas.mean()),
                    "std": float(four_stage_personas.std()) if len(four_stage_personas) > 1 else 0.0,
                    "count": int(len(four_stage_personas))
                },
                "difference": float(two_stage_personas.mean() - four_stage_personas.mean()),
                "note": "å¯¹æ¯”æœ‰æ„ä¹‰ï¼š2 Stageä½¿ç”¨consolidatedç”Ÿæˆï¼Œ4 Stageä½¿ç”¨ç‹¬ç«‹ç”Ÿæˆã€‚æ³¨æ„ï¼š3 Stageå’Œ4 Stageçš„Personasç›¸åŒï¼Œæ— éœ€å¯¹æ¯”"
            }

        # 2. Mappingså¯¹æ¯”ï¼š2 Stage vs 3 Stage vs 4 Stageï¼ˆç”Ÿæˆæ–¹æ³•ä¸åŒï¼‰
        two_stage_mappings = df[df["architecture"] == "Two-Stage"]["num_mappings"]
        three_stage_mappings = df[df["architecture"] == "Three-Stage"]["num_mappings"]
        four_stage_mappings = df[df["architecture"] == "Four-Stage"]["num_mappings"]

        if len(two_stage_mappings) > 0 and len(three_stage_mappings) > 0 and len(four_stage_mappings) > 0:
            comparison["mappings_comparison"] = {
                "two_stage": {
                    "avg": float(two_stage_mappings.mean()),
                    "std": float(two_stage_mappings.std()) if len(two_stage_mappings) > 1 else 0.0,
                    "count": int(len(two_stage_mappings))
                },
                "three_stage": {
                    "avg": float(three_stage_mappings.mean()),
                    "std": float(three_stage_mappings.std()) if len(three_stage_mappings) > 1 else 0.0,
                    "count": int(len(three_stage_mappings))
                },
                "four_stage": {
                    "avg": float(four_stage_mappings.mean()),
                    "std": float(four_stage_mappings.std()) if len(four_stage_mappings) > 1 else 0.0,
                    "count": int(len(four_stage_mappings))
                },
                "best": max(
                    ("Two-Stage", two_stage_mappings.mean()),
                    ("Three-Stage", three_stage_mappings.mean()),
                    ("Four-Stage", four_stage_mappings.mean()),
                    key=lambda x: x[1]
                )[0],
                "note": "å¯¹æ¯”æœ‰æ„ä¹‰ï¼š2/3 Stageä¸€èµ·ç”Ÿæˆï¼Œ4 Stageç‹¬ç«‹ç”Ÿæˆ"
            }

        # 3. Sequenceså¯¹æ¯”ï¼š2 Stage vs 3 Stage vs 4 Stageï¼ˆç”Ÿæˆæ–¹æ³•ä¸åŒï¼‰
        two_stage_sequences = df[df["architecture"] == "Two-Stage"]["num_sequences"]
        three_stage_sequences = df[df["architecture"] == "Three-Stage"]["num_sequences"]
        four_stage_sequences = df[df["architecture"] == "Four-Stage"]["num_sequences"]

        if len(two_stage_sequences) > 0 and len(three_stage_sequences) > 0 and len(four_stage_sequences) > 0:
            comparison["sequences_comparison"] = {
                "two_stage": {
                    "avg": float(two_stage_sequences.mean()),
                    "std": float(two_stage_sequences.std()) if len(two_stage_sequences) > 1 else 0.0,
                    "count": int(len(two_stage_sequences))
                },
                "three_stage": {
                    "avg": float(three_stage_sequences.mean()),
                    "std": float(three_stage_sequences.std()) if len(three_stage_sequences) > 1 else 0.0,
                    "count": int(len(three_stage_sequences))
                },
                "four_stage": {
                    "avg": float(four_stage_sequences.mean()),
                    "std": float(four_stage_sequences.std()) if len(four_stage_sequences) > 1 else 0.0,
                    "count": int(len(four_stage_sequences))
                },
                "best": max(
                    ("Two-Stage", two_stage_sequences.mean()),
                    ("Three-Stage", three_stage_sequences.mean()),
                    ("Four-Stage", four_stage_sequences.mean()),
                    key=lambda x: x[1]
                )[0],
                "note": "å¯¹æ¯”æœ‰æ„ä¹‰ï¼š2/3 Stageä¸€èµ·ç”Ÿæˆï¼Œ4 Stageç‹¬ç«‹ç”Ÿæˆ"
            }

        # 4. æ•´ä½“æ€§èƒ½å¯¹æ¯”ï¼šæ‰€æœ‰æ¶æ„
        comparison["overall_performance"] = {}
        comparison["outliers"] = {}  # è®°å½•å¼‚å¸¸å€¼ä¿¡æ¯
        
        for arch in ["Two-Stage", "Three-Stage", "Four-Stage"]:
            arch_df = df[df["architecture"] == arch]
            if len(arch_df) > 0:
                # å¯¹äºThree-Stageçš„æ—¶é—´ï¼Œç§»é™¤å¼‚å¸¸å€¼
                if arch == "Three-Stage":
                    time_series = arch_df["total_time_seconds"]
                    time_without_outliers = remove_outliers(time_series, method="iqr", multiplier=1.5)
                    
                    # è®°å½•å¼‚å¸¸å€¼ä¿¡æ¯
                    outliers = time_series[~time_series.index.isin(time_without_outliers.index)]
                    if len(outliers) > 0:
                        outlier_companies = arch_df.loc[outliers.index, "company_name"].tolist()
                        outlier_times = outliers.tolist()
                        comparison["outliers"][arch] = {
                            "companies": outlier_companies,
                            "times": outlier_times,
                            "count": len(outliers)
                        }
                    
                    # ä½¿ç”¨ç§»é™¤å¼‚å¸¸å€¼åçš„æ•°æ®è®¡ç®—å¹³å‡æ—¶é—´
                    avg_time = float(time_without_outliers.mean()) if len(time_without_outliers) > 0 else float(time_series.mean())
                    count_without_outliers = len(time_without_outliers)
                else:
                    avg_time = float(arch_df["total_time_seconds"].mean())
                    count_without_outliers = len(arch_df)
                
                comparison["overall_performance"][arch] = {
                    "avg_tokens": float(arch_df["total_tokens"].mean()),
                    "avg_time_seconds": avg_time,
                    "avg_time_seconds_with_outliers": float(arch_df["total_time_seconds"].mean()) if arch == "Three-Stage" else None,
                    "avg_mappings": float(arch_df["num_mappings"].mean()),
                    "avg_sequences": float(arch_df["num_sequences"].mean()),
                    "count": int(len(arch_df)),
                    "count_without_outliers": count_without_outliers if arch == "Three-Stage" else None
                }

        # æ·»åŠ æ—¶é—´å’ŒTokenåˆ†æ
        comparison["time_token_analysis"] = self.generate_time_token_analysis(df)

        # æ·»åŠ è¯´æ˜
        comparison["notes"] = [
            "Personaså¯¹æ¯”ï¼šåªå¯¹æ¯”2 Stage vs 4 Stageï¼ˆ3 Stageå’Œ4 Stageçš„Personasç›¸åŒï¼Œæ— éœ€å¯¹æ¯”ï¼‰",
            "Mappingså¯¹æ¯”ï¼šå¯¹æ¯”2 Stage vs 3 Stage vs 4 Stageï¼ˆç”Ÿæˆæ–¹æ³•ä¸åŒï¼‰",
            "Sequenceså¯¹æ¯”ï¼šå¯¹æ¯”2 Stage vs 3 Stage vs 4 Stageï¼ˆç”Ÿæˆæ–¹æ³•ä¸åŒï¼‰",
            "æ³¨æ„ï¼š3 Stageå’Œ4 Stageçš„Personasç”Ÿæˆæ–¹æ³•ç›¸åŒï¼Œæ‰€ä»¥åªå¯¹æ¯”2 Stageå’Œ4 Stage",
            "æ³¨æ„ï¼š3 Stageå’Œ4 Stageçš„Productsç”Ÿæˆæ–¹æ³•ç›¸åŒï¼Œæ— éœ€å¯¹æ¯”"
        ]

        return comparison

    def save_results(self, df: pd.DataFrame, output_dir: Path = Path("evaluation_results")):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        output_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜è¯¦ç»†æ•°æ® CSV
        csv_path = output_dir / f"detailed_metrics_{timestamp}.csv"
        df.to_csv(csv_path, index=False)
        print(f"âœ… è¯¦ç»†æŒ‡æ ‡å·²ä¿å­˜åˆ°: {csv_path}")

        # ä¿å­˜è¯¦ç»†æ•°æ® JSONï¼ˆåŒ…å«æ¯ä¸ªå…¬å¸çš„è¯¦ç»†æŒ‡æ ‡ï¼‰
        detailed_json_path = output_dir / f"detailed_metrics_{timestamp}.json"
        detailed_data = df.to_dict(orient='records')
        with open(detailed_json_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_data, f, indent=2, ensure_ascii=False)
        print(f"âœ… è¯¦ç»†æŒ‡æ ‡ JSON å·²ä¿å­˜åˆ°: {detailed_json_path}")

        # ç”Ÿæˆæœ‰æ„ä¹‰çš„å¯¹æ¯”æŠ¥å‘Š
        comparison = self.generate_meaningful_comparison(df)
        comparison_path = output_dir / f"meaningful_comparison_{timestamp}.json"
        with open(comparison_path, 'w', encoding='utf-8') as f:
            json.dump(comparison, f, indent=2, ensure_ascii=False)
        print(f"âœ… æœ‰æ„ä¹‰å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜åˆ°: {comparison_path}")

        # ç”Ÿæˆå¯¹æ¯”CSVï¼ˆåªåŒ…å«æœ‰æ„ä¹‰çš„å¯¹æ¯”ï¼‰
        comparison_csv_path = output_dir / f"meaningful_comparison_{timestamp}.csv"
        comparison_df = df.groupby("architecture").agg({
            "num_personas": ["mean", "std", "count"],
            "num_mappings": ["mean", "std", "count"],
            "num_sequences": ["mean", "std", "count"],
            "num_touches": ["mean", "std"],
            "total_tokens": ["mean", "std", "min", "max"],
            "total_time_seconds": ["mean", "std", "min", "max"],
            "prompt_tokens": ["mean", "sum"],
            "completion_tokens": ["mean", "sum"],
        }).round(2)
        comparison_df.to_csv(comparison_csv_path)
        print(f"âœ… å¯¹æ¯”æ•°æ®å·²ä¿å­˜åˆ°: {comparison_csv_path}")

        # ç”Ÿæˆæ—¶é—´å’ŒTokenè¯¦ç»†å¯¹æ¯”CSV
        if comparison.get("time_token_analysis"):
            tta = comparison["time_token_analysis"]
            time_token_csv_path = output_dir / f"time_token_analysis_{timestamp}.csv"
            
            # æ„å»ºæ—¶é—´å’ŒTokenå¯¹æ¯”è¡¨
            time_token_rows = []
            for arch in ["Two-Stage", "Three-Stage", "Four-Stage"]:
                if arch in tta.get("time_analysis", {}):
                    row = {
                        "Architecture": arch,
                        "Avg_Time_Seconds": tta["time_analysis"][arch]["mean_without_outliers"],
                        "Median_Time_Seconds": tta["time_analysis"][arch]["median"],
                        "Std_Time_Seconds": tta["time_analysis"][arch]["std"],
                        "Min_Time_Seconds": tta["time_analysis"][arch]["min"],
                        "Max_Time_Seconds": tta["time_analysis"][arch]["max"],
                        "Avg_Total_Tokens": tta["token_analysis"][arch]["total_tokens_mean"],
                        "Median_Total_Tokens": tta["token_analysis"][arch]["total_tokens_median"],
                        "Std_Total_Tokens": tta["token_analysis"][arch]["total_tokens_std"],
                        "Min_Total_Tokens": tta["token_analysis"][arch]["total_tokens_min"],
                        "Max_Total_Tokens": tta["token_analysis"][arch]["total_tokens_max"],
                        "Avg_Prompt_Tokens": tta["token_analysis"][arch]["prompt_tokens_mean"],
                        "Avg_Completion_Tokens": tta["token_analysis"][arch]["completion_tokens_mean"],
                        "Prompt_Ratio_Percent": tta["token_analysis"][arch]["prompt_ratio"],
                        "Completion_Ratio_Percent": tta["token_analysis"][arch]["completion_ratio"],
                        "Tokens_Per_Second": tta["efficiency_metrics"][arch]["tokens_per_second"],
                        "Mappings_Per_Token": tta["efficiency_metrics"][arch]["mappings_per_token"],
                        "Sequences_Per_Token": tta["efficiency_metrics"][arch]["sequences_per_token"],
                        "Mappings_Per_Second": tta["efficiency_metrics"][arch]["mappings_per_second"],
                        "Sequences_Per_Second": tta["efficiency_metrics"][arch]["sequences_per_second"],
                        "Time_Per_Mapping": tta["efficiency_metrics"][arch]["time_per_mapping"],
                        "Time_Per_Sequence": tta["efficiency_metrics"][arch]["time_per_sequence"],
                    }
                    
                    # æ·»åŠ ç›¸å¯¹äº2-Stageçš„å˜åŒ–ï¼ˆå¦‚æœæ˜¯3-Stageæˆ–4-Stageï¼‰
                    if arch in tta.get("comparison_summary", {}):
                        cs = tta["comparison_summary"][arch]
                        row["Time_Change_vs_2Stage_Seconds"] = cs["time_vs_two_stage"]["absolute_change"]
                        row["Time_Change_vs_2Stage_Percent"] = cs["time_vs_two_stage"]["percentage_change"]
                        row["Time_Multiplier_vs_2Stage"] = cs["time_vs_two_stage"]["multiplier"]
                        row["Token_Change_vs_2Stage"] = cs["tokens_vs_two_stage"]["absolute_change"]
                        row["Token_Change_vs_2Stage_Percent"] = cs["tokens_vs_two_stage"]["percentage_change"]
                        row["Token_Multiplier_vs_2Stage"] = cs["tokens_vs_two_stage"]["multiplier"]
                    else:
                        row["Time_Change_vs_2Stage_Seconds"] = 0
                        row["Time_Change_vs_2Stage_Percent"] = 0
                        row["Time_Multiplier_vs_2Stage"] = 1.0
                        row["Token_Change_vs_2Stage"] = 0
                        row["Token_Change_vs_2Stage_Percent"] = 0
                        row["Token_Multiplier_vs_2Stage"] = 1.0
                    
                    time_token_rows.append(row)
            
            time_token_df = pd.DataFrame(time_token_rows)
            time_token_df.to_csv(time_token_csv_path, index=False)
            print(f"âœ… æ—¶é—´å’ŒTokenè¯¦ç»†åˆ†æå·²ä¿å­˜åˆ°: {time_token_csv_path}")

        # æ‰“å°æ±‡æ€»ç»Ÿè®¡
        self.print_summary(comparison, df)

        return output_dir

    def print_summary(self, comparison: Dict, df: pd.DataFrame):
        """æ‰“å°æ±‡æ€»ç»Ÿè®¡"""
        print("\n" + "=" * 80)
        print("è¯„ä¼°ç»“æœæ±‡æ€»ï¼ˆåªåŒ…å«æœ‰æ„ä¹‰çš„å¯¹æ¯”ï¼‰")
        print("=" * 80)

        print("\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   - å…¬å¸æ•°é‡: {df['company_name'].nunique()}")
        print(f"   - æ¶æ„æ•°é‡: {df['architecture'].nunique()}")
        print(f"   - æ€»è¿è¡Œæ¬¡æ•°: {len(df)}")

        # Personaså¯¹æ¯”ï¼ˆ2 Stage vs 4 Stageï¼‰
        if comparison.get("personas_comparison"):
            pc = comparison["personas_comparison"]
            print("\nğŸ‘¥ Personaså¯¹æ¯”ï¼ˆ2 Stage vs 4 Stageï¼‰:")
            print(f"   2 Stage: å¹³å‡ {pc['two_stage']['avg']:.1f} ä¸ª (n={pc['two_stage']['count']})")
            print(f"   4 Stage: å¹³å‡ {pc['four_stage']['avg']:.1f} ä¸ª (n={pc['four_stage']['count']})")
            print(f"   å·®å¼‚: {pc['difference']:.1f}")
            print(f"   è¯´æ˜: {pc['note']}")

        # Mappingså¯¹æ¯”ï¼ˆ2 Stage vs 3 Stage vs 4 Stageï¼‰
        if comparison.get("mappings_comparison"):
            mc = comparison["mappings_comparison"]
            print("\nğŸ”— Mappingså¯¹æ¯”ï¼ˆ2 Stage vs 3 Stage vs 4 Stageï¼‰:")
            print(f"   2 Stage: å¹³å‡ {mc['two_stage']['avg']:.1f} ä¸ª (n={mc['two_stage']['count']})")
            print(f"   3 Stage: å¹³å‡ {mc['three_stage']['avg']:.1f} ä¸ª (n={mc['three_stage']['count']})")
            print(f"   4 Stage: å¹³å‡ {mc['four_stage']['avg']:.1f} ä¸ª (n={mc['four_stage']['count']})")
            print(f"   æœ€ä½³: {mc['best']}")
            print(f"   è¯´æ˜: {mc['note']}")

        # Sequenceså¯¹æ¯”ï¼ˆ2 Stage vs 3 Stage vs 4 Stageï¼‰
        if comparison.get("sequences_comparison"):
            sc = comparison["sequences_comparison"]
            print("\nğŸ“§ Sequenceså¯¹æ¯”ï¼ˆ2 Stage vs 3 Stage vs 4 Stageï¼‰:")
            print(f"   2 Stage: å¹³å‡ {sc['two_stage']['avg']:.1f} ä¸ª (n={sc['two_stage']['count']})")
            print(f"   3 Stage: å¹³å‡ {sc['three_stage']['avg']:.1f} ä¸ª (n={sc['three_stage']['count']})")
            print(f"   4 Stage: å¹³å‡ {sc['four_stage']['avg']:.1f} ä¸ª (n={sc['four_stage']['count']})")
            print(f"   æœ€ä½³: {sc['best']}")
            print(f"   è¯´æ˜: {sc['note']}")

        # æ•´ä½“æ€§èƒ½
        if comparison.get("overall_performance"):
            print("\nâš¡ æ•´ä½“æ€§èƒ½å¯¹æ¯”:")
            for arch, perf in comparison["overall_performance"].items():
                print(f"   {arch}:")
                print(f"      - å¹³å‡Token: {perf['avg_tokens']:,.0f}")
                if perf.get('avg_time_seconds_with_outliers') is not None:
                    # Three-Stageæ˜¾ç¤ºæ’é™¤å¼‚å¸¸å€¼åçš„æ—¶é—´
                    print(f"      - å¹³å‡æ—¶é—´: {perf['avg_time_seconds']:.1f}ç§’ (æ’é™¤å¼‚å¸¸å€¼å, n={perf['count_without_outliers']})")
                    print(f"      - å¹³å‡æ—¶é—´(å«å¼‚å¸¸å€¼): {perf['avg_time_seconds_with_outliers']:.1f}ç§’ (n={perf['count']})")
                else:
                    print(f"      - å¹³å‡æ—¶é—´: {perf['avg_time_seconds']:.1f}ç§’")
                print(f"      - å¹³å‡Mappings: {perf['avg_mappings']:.1f}")
                print(f"      - å¹³å‡Sequences: {perf['avg_sequences']:.1f}")
            
            # æ˜¾ç¤ºå¼‚å¸¸å€¼ä¿¡æ¯
            if comparison.get("outliers"):
                print("\nğŸ” å¼‚å¸¸å€¼æ£€æµ‹:")
                for arch, outlier_info in comparison["outliers"].items():
                    print(f"   {arch}:")
                    for i, (company, time) in enumerate(zip(outlier_info["companies"], outlier_info["times"])):
                        print(f"      - {company}: {time:.1f}ç§’ (å·²æ’é™¤)")

        # æ—¶é—´å’ŒTokenè¯¦ç»†åˆ†æ
        if comparison.get("time_token_analysis"):
            tta = comparison["time_token_analysis"]
            
            print("\nâ±ï¸  æ—¶é—´æ¶ˆè€—è¯¦ç»†åˆ†æ:")
            for arch in ["Two-Stage", "Three-Stage", "Four-Stage"]:
                if arch in tta.get("time_analysis", {}):
                    ta = tta["time_analysis"][arch]
                    print(f"   {arch}:")
                    print(f"      - å¹³å‡æ—¶é—´: {ta['mean']:.1f}ç§’ (æ’é™¤å¼‚å¸¸å€¼å: {ta['mean_without_outliers']:.1f}ç§’)")
                    print(f"      - ä¸­ä½æ•°: {ta['median']:.1f}ç§’")
                    print(f"      - æ ‡å‡†å·®: {ta['std']:.1f}ç§’")
                    print(f"      - èŒƒå›´: {ta['min']:.1f} - {ta['max']:.1f}ç§’")
                    print(f"      - æ ·æœ¬æ•°: {ta['count']} (æ’é™¤å¼‚å¸¸å€¼å: {ta['count_without_outliers']})")
            
            print("\nğŸ”¢ Tokenæ¶ˆè€—è¯¦ç»†åˆ†æ:")
            for arch in ["Two-Stage", "Three-Stage", "Four-Stage"]:
                if arch in tta.get("token_analysis", {}):
                    toa = tta["token_analysis"][arch]
                    print(f"   {arch}:")
                    print(f"      - å¹³å‡æ€»Token: {toa['total_tokens_mean']:,.0f}")
                    print(f"      - ä¸­ä½æ•°: {toa['total_tokens_median']:,.0f}")
                    print(f"      - èŒƒå›´: {toa['total_tokens_min']:,.0f} - {toa['total_tokens_max']:,.0f}")
                    print(f"      - å¹³å‡Prompt Token: {toa['prompt_tokens_mean']:,.0f} ({toa['prompt_ratio']:.1f}%)")
                    print(f"      - å¹³å‡Completion Token: {toa['completion_tokens_mean']:,.0f} ({toa['completion_ratio']:.1f}%)")
            
            print("\nğŸ“Š æ•ˆç‡æŒ‡æ ‡å¯¹æ¯”:")
            for arch in ["Two-Stage", "Three-Stage", "Four-Stage"]:
                if arch in tta.get("efficiency_metrics", {}):
                    em = tta["efficiency_metrics"][arch]
                    print(f"   {arch}:")
                    print(f"      - Token/ç§’: {em['tokens_per_second']:.1f}")
                    print(f"      - Mappings/Token: {em['mappings_per_token']:.4f}")
                    print(f"      - Sequences/Token: {em['sequences_per_token']:.4f}")
                    print(f"      - Mappings/ç§’: {em['mappings_per_second']:.2f}")
                    print(f"      - Sequences/ç§’: {em['sequences_per_second']:.2f}")
                    print(f"      - æ—¶é—´/Mapping: {em['time_per_mapping']:.2f}ç§’")
                    print(f"      - æ—¶é—´/Sequence: {em['time_per_sequence']:.2f}ç§’")
            
            print("\nğŸ“ˆ ç›¸å¯¹äº2-Stageçš„å˜åŒ–:")
            for arch in ["Three-Stage", "Four-Stage"]:
                if arch in tta.get("comparison_summary", {}):
                    cs = tta["comparison_summary"][arch]
                    print(f"   {arch}:")
                    time_change = cs["time_vs_two_stage"]
                    token_change = cs["tokens_vs_two_stage"]
                    print(f"      æ—¶é—´å˜åŒ–:")
                    print(f"         - ç»å¯¹å˜åŒ–: {time_change['absolute_change']:+.1f}ç§’")
                    print(f"         - ç™¾åˆ†æ¯”å˜åŒ–: {time_change['percentage_change']:+.1f}%")
                    print(f"         - å€æ•°: {time_change['multiplier']:.2f}x")
                    print(f"      Tokenå˜åŒ–:")
                    print(f"         - ç»å¯¹å˜åŒ–: {token_change['absolute_change']:+,.0f}")
                    print(f"         - ç™¾åˆ†æ¯”å˜åŒ–: {token_change['percentage_change']:+.1f}%")
                    print(f"         - å€æ•°: {token_change['multiplier']:.2f}x")

        # æ³¨æ„äº‹é¡¹
        if comparison.get("notes"):
            print("\nâš ï¸  æ³¨æ„äº‹é¡¹:")
            for note in comparison["notes"]:
                print(f"   - {note}")
            if comparison.get("outliers"):
                print(f"   - Three-Stageçš„å¹³å‡æ—¶é—´å·²æ’é™¤å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹ï¼‰")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è¯„ä¼°Pipelineç»“æœ...")
    print(f"ğŸ“ è¯„ä¼°ç›®å½•: {EVALUATION_DIR}")

    if not EVALUATION_DIR.exists():
        print(f"âŒ é”™è¯¯: è¯„ä¼°ç›®å½•ä¸å­˜åœ¨: {EVALUATION_DIR}")
        return

    evaluator = PipelineEvaluator(EVALUATION_DIR)

    # è¯„ä¼°æ‰€æœ‰æ•°æ®
    df = evaluator.evaluate_all()

    if df.empty:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è¯„ä¼°æ•°æ®")
        return

    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è¯„ä¼°è®°å½•")
    print(f"   å…¬å¸: {df['company_name'].nunique()} ä¸ª")
    print(f"   æ¶æ„: {df['architecture'].nunique()} ç§")
    print(f"   æ¶æ„åˆ—è¡¨: {sorted(df['architecture'].unique())}")

    # ä¿å­˜ç»“æœ
    output_dir = evaluator.save_results(df)

    print(f"\nâœ¨ è¯„ä¼°å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")


if __name__ == "__main__":
    main()

